---
layout: post
title: "Developing a Deep Learning Framework in Rust"
date: 2017-05-19
---

There are numerous deep learning frameworks available. Judging by the number of stars on github 
and the amount attention that Google has given it, the most well known is probably Google's 
TensorFlow. For most applications, which framework is 'best' ultimately boils down to taste and
implementation details for the specific model one is developing. Of the handful that I've tried, the first framework that I've actually *enjoyed* using is PyTorch.

The simplest example that actually does something interesting is MNIST - classifying handwritten digits:

    class Net(nn.Module):
        def __init__(self):
            super(Net, self).__init__()
            self.conv1 = nn.Conv2d(1, 10, kernel_size=5)
            self.conv2 = nn.Conv2d(10, 20, kernel_size=5)
            self.conv2_drop = nn.Dropout2d()
            self.fc1 = nn.Linear(320, 50)
            self.fc2 = nn.Linear(50, 10)

        def forward(self, x):
            x = F.relu(F.max_pool2d(self.conv1(x), 2))
            x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))
            x = x.view(-1, 320)
            x = F.relu(self.fc1(x))
            x = F.dropout(x, training=self.training)
            x = self.fc2(x)
            return F.log_softmax(x)
            
If *data* is a 2d tensor representing a grey scale image and *target* is the correct value and optimizer is one of the available optimizers - SGD, ADAM, RMSprop, etc. - instantiating the model and doing a single training pass is
    
        model = Net()
        ...
(eliding a number of critical details for the sake of clarity)

        output = model(data)
        loss = F.nll_loss(output, target)
        loss.backward()
        optimizer.step()
        
Calling model calls forward(data) followed by any registered forward and backward hooks. Inheriting from nn.Module let Net automatically construct a graph used for bookkeeping purposes: setting training state, tensor primitive type, location of tensor (CPU/GPU), serialization/deserialization, and pretty printing.

Although Python is a great language for exploration of ideas there are environments for which it is not a good fit. The ones that come first to mind are embedded and linked against native applications in a server environment. Facebook, the primary sponsor of PyTorch, uses Caffe2 (a single rather large C++ binary) for production within its Applied Machine Learning group. Although this is certainly a pragmatic choice, I would like to have something lighter weight with the flexibility of PyTorch. To this end I've started developing Rust bindings for the Torch C libraries with an aim to providing an API as close to the one provided by PyTorch as Rust will permit. I've chosen the logical and yet whimsical name torch.rs (torturous) for this
DL framework. As a systems language that aims to have performance equivalent to C Rust is a much less compliant language than python so the framework does face the very real risk of being a dancing bear.


Based on the syntactic issues I've resolved far, an implementation of the Net class in the MNIST example shown above in torch.rs should look something like:

    #[derive(ModuleParse)]
    struct Net<'a> {
        delegate: Module<'a>,
        #[module]
        conv1: Conv2d,
        #[module]
        conv2: Conv2d,
        #[module]
        conv2_drop: Dropout2d,
        #[module]
        fc1: Linear,
        #[module]
        fc2: Linear,
    }
    impl Net<'a> {
        pub fn new() -> Net<'a> {
            let t = Net {
            delegate: Module::new(),
            conv1: Conv2d::new(Conv2dArgs {
                                in_channels: 1,
                                out_channels: 10,
                                kernel_size: 5, ...}),
            conv2: Conv2d::new(Conv2dArgs {
                                in_channels: 10,
                                out_channels: 20,
                                kernel_size: 5, ...}),
            conv2_drop: Dropout2d::new(0.5),
            fc1: Linear::new(320, 50, true),
            fc2: Linear::new(50, 10, true),
            };
            t.init_module();
            t 
        }
    }
    impl <'a>ModIntf<'a> for Net<'a> {
        fn forward(&mut self, args: &[&mut Tensor]) -> [&mut Tensor] {
            let x = F.relu(F.max_pool2d(self.conv1(&args[0]), 2));
            let x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(&x)), 2)));
            let x = x.view(-1, 320);
            let x = F.relu(self.fc1(x));
            let x = F.dropout(x, self.delegate.training, 0.5)
            let x = self.fc2(x);
            F.log_softmax(x)
        }
        fn delegate(&mut self) -> &mut Module<'a> { &mut self.delegate }
    }


While certainly more verbose than the PyTorch version, I think it actually does a reasonable job of capturing the spirit of the PyTorch API. In descending order of severity, the added complexity and syntax mismatch stem from the following missing features from and design limits of Rust:
- No compositional inheritance
- No introspection
- No optional named arguments (kwargs)
- Only one mutable reference allowed at a time
- Overloading indexing operator '[]' only allows one argument


As of 1.19 Rust does not support anything resembling compositional inheritance. This means that the familiar pattern:

    Base {
        fieldA;
        methodA();
        virtual methodB();
    }
    Subtype extends Base {
        fieldB;
        methodB() {...}
        methodC() {...}
    }

where *Subtype* will automatically embed *Base*, one can call *.methodA()* on an instance of *Subtype*, and all classes subtyping Base will support *.methodB()* - will not work in Rust. In Rust one can achieve a similar effect with the following idiom:

    struct Base {
        fieldA : atype,
    }
    impl Base {
        fn methodA(&self) -> atype { ... }
    }
    trait BaseIntf {
        fn delegate(&mut self) -> &mut Base;
        fn methodA(&mut self) -> atype { self.delegate().methodA() }
        fn methodB(&self) -> atype; 
    }
    struct Subtype {
        delegate: Base,
        fieldB: atype,
    }
    impl Subtype {
        fn methodC(&self) -> atype { ... }
    }
    impl BaseIntf for Subtype {
        fn delegate(&mut self) -> &mut Base { &mut self.delegate }
        fn methodB(&self) -> atype { ... }
    }

One can explicitly create the *Subtype* "is a" *Base* relationship while separately defining the common set of interfaces that classes inheriting from Base should support and thus support the semantics that OO languages support more automatically. This is why the torch.rs version of MNIST embeds a module and implements a *delegate()* method.


    

- Indexing limits
    - array args
    - separate function for slices
- lack of kwargs
    - default initializer
- lack of compositional inheritance
    - Implement FooBase struct with fields and functions only using base fields
    - Define trait that "inheriting" structs will implement to allow them to
      be passed to Base
- lack of introspection 
    - define derive procedural macro
        - match against type name when only a single type is in use
        - annotate when derived types are used
    - call derived function in derived type initializer
- single mutable reference
    - can't iterate over children as done in python
    - two possible workarounds:
        - generate vector of field names and function to map fielld names to fields
          at runtime
        - store as raw pointers
           - cast to raw pointer when storing in HashMap
           - cast back to reference in wrapper iterator
           
Next steps:
    Figuring out the implementation details of autograd
    

